
---

# 要件定義書: SCPデータ取得MCPサーバ

### 0. 文書情報

* 文書名：SCPデータ取得MCPサーバ 要件定義書
* 版：v0.1（ドラフト）
* 作成日：2026-01-15
* 準拠プロトコル：Model Context Protocol（仕様ページの現行改訂を基準に実装し、初期化時にバージョンネゴシエーションを行う）([Model Context Protocol][4])

---

### 1. 背景・目的

* SCP Wiki由来のページ本文・メタデータを、LLMが**検索・取得・引用**できる形で提供する。
* 取得対象は、SCP番号（例：SCP-173）・ページslug（例：`scp-173`）・タグ・シリーズ・ハブ等を起点に、AIが必要なコンテキストを機械的に取得できること。
* MCPサーバとして公開し、MCPクライアント（Claude/ChatGPT/IDE/自作エージェント等）から同一インターフェースで利用可能にする。([Model Context Protocol][4])
* 当面は外部APIのラッパーとしてオンデマンド取得を行い、永続データベースは持たない。キャッシュはプロセス内メモリに限定する。

---

### 2. 対象範囲

#### 2.1 スコープ（含む）

* SCP記事（Items）・Tales・GOI・Hubs（少なくとも英語本家データ）
* ページメタデータ：タイトル、URL、タグ、レーティング、作成日時、改訂履歴、画像URL等（データソースが提供する範囲）
* 本文コンテンツ：Wikidotソース（raw_source）およびレンダリング済みHTML断片（raw_content）を取得し、AI向けに正規化したテキスト/Markdownを生成
* ライセンス/帰属情報の付与（後述）

#### 2.2 スコープ（含まない / 将来拡張）

* SCP Wikiのアカウント操作（投稿/編集/投票）
* WikidotのAPIキー前提機能を必須要件にしない（使えるなら補助的に利用）
* 画像ファイルそのもののミラー配信（URLの提示まで）
* ローカルDB/オブジェクトストレージへのミラー運用（将来拡張）

---

### 3. データソース要件

#### 3.1 優先データソース（必須）

* **SCP Data API** を一次ソースとして採用（静的JSONダンプ・日次更新）。([scp-api][1])

  * 必須取得項目（最低限）

    * `link`（slug）
    * `title`
    * `url`
    * `page_id`（Wikidot page id）([scp-api][1])
    * `tags` / `rating`
    * `created_at`
    * `history`（可能なら）
    * `content_file` or `raw_content`/`raw_source`（本文取得用）([scp-api][1])

#### 3.3 データ更新

* SCP Data APIは日次更新を前提とする。MCPはオンデマンド取得を基本とし、定期的な取り込み（pull）は行わない。([scp-api][1])
* 取り込み方式（採用）：

  * (A) オンデマンド取得 + 強キャッシュ（Etag/If-Modified-Since相当）
    * キャッシュはプロセス内メモリに限定し、永続化しない（再起動で失効）

---

### 4. ライセンス・コンプライアンス要件（必須）

SCP Wikiのコンテンツは **CC BY-SA 3.0** を前提とし、派生物（サービス提供物）にも帰属とライセンス表記が必要。([SCP Foundation][6])
要件：

1. 各取得結果に、最低限以下を含めて返す

   * 出典ページURL
   * 作品名（ページタイトル）
   * 作者（取得可能な範囲で）
   * ライセンス名（CC BY-SA 3.0）とその参照URL
     ([SCP Foundation][6])
2. SCP-173の「過去の画像（Izumi Kato作品）」は商用利用NGである旨を、画像/メディア関連の出力に含められる設計（フィルタまたは注意書き）にする。([SCP Foundation][6])
3. サーバのREADME/メタ情報として「非公式」「ライセンス遵守が必要」を明示する。([scp-api][1])

---

### 5. 機能要件

#### 5.1 MCPサーバ基本要件

* MCPサーバは以下を提供する：

  * Tools（関数呼び出し）
  * Resources（データ参照）
  * Prompts（定型ワークフロー）
    ([Model Context Protocol][4])
* 通信はJSON-RPC 2.0。([Model Context Protocol][4])
* トランスポート：

  * stdio（ローカル統合用）
  * Streamable HTTP（本番/リモート運用用）
    ([Model Context Protocol][5])

#### 5.2 Tools（必須）

以下は最小セット（MVP）。戻り値はすべてJSONで、`license` と `attribution` を必ず含む。

1. `scp_search`

* 目的：キーワード/タグ/シリーズでページ候補を返す
* 入力例：

  * `query`（文字列）
  * `site`（例：`en` / `ja`。データ対応範囲で有効化）([GitHub][2])
  * `tags`（配列、任意）
  * `series`（任意）
  * `limit`（上限、デフォルト20）
  * `sort`（`relevance|rating|created_at` など）
* 出力：

  * `results[]`: `{link,title,url,page_id,rating,tags,created_at,snippet}`

2. `scp_get_page`

* 目的：ページを一意に取得
* 入力：`link`（slug）または `scp_number`（数値）または `page_id`
* 出力：

  * `page`: メタデータ一式
  * `content`: （オプション）本文（後述の整形済み）
  * `license` / `attribution`

3. `scp_get_content`

* 目的：本文を取得（大型ページ用に分離）
* 入力：

  * `link` または `page_id`
  * `format`：`markdown|text|html|wikitext`
  * `include_tables` / `include_footnotes`（任意）
* 出力：

  * `content`（指定形式）
  * `source`: `{url, title, page_id}`
  * `license` / `attribution`

4. `scp_get_related`

* 目的：参照/ハブ関係から関連ページを返す（ナビゲーション用）
* 入力：`link`
* 出力：`related[]`（link, title, url, relation_type）

5. `scp_get_attribution`

* 目的：二次利用に必要な帰属テキストを機械生成（テンプレ）
* 入力：`link`
* 出力：

  * `attribution_text`（CC BY-SA 3.0準拠の記載例）
  * `authors`（取得できた範囲）
  * `license`（CC BY-SA 3.0）

#### 5.4 Prompts

* `prompt_quote_with_citation`：取得したSCP本文から「引用付き回答」を行うための定型（「出典URLと作者とライセンスを必ず含める」など）
* `prompt_rag_reader`：検索→取得→要約の一連を安全に行うための定型

---

### 6. コンテンツ正規化要件（AI可読化）

* 入力として `raw_source`（Wikidotソース）と `raw_content`（HTML断片）があり得る。([scp-api][1])
* 出力形式：

  * `markdown`（推奨デフォルト）
  * `plain text`
  * `html`（必要時）
  * `wikitext`（raw_source）
* 正規化処理（推奨）：

  * ナビゲーション/フッタ等の除去（データソース側で `#page-content` を使う前提がある）([scp-api][1])
  * 折りたたみ/脚注を展開または参照リンク化
  * 見出し階層の維持
  * 画像は本文埋め込みではなく「画像URL一覧」として別フィールドで返す（必要ならaltテキストも生成）

---

### 7. 検索要件

* 最低限：全文（title + altTitle相当 + 本文）に対するキーワード検索
* フィルタ：タグ、シリーズ、作成日範囲、レーティング範囲
* スコアリング：BM25等のキーワード検索 + 追加でrating/新しさ補正（任意）

---

### 8. セキュリティ要件

MCPは「任意データアクセス/ツール実行」を扱えるため、信頼・安全設計が重要。([Model Context Protocol][4])

* 外部コンテンツ（SCP本文）は**不正な命令（prompt injection）を含み得る“非信頼データ”**として扱う

  * MCPツールの戻り値に `content_is_untrusted: true` 等のメタを付与
  * 可能なら本文は「データとして扱え」と明示するサニタイズ注記を付与
* SSRF対策：サーバが任意URLをフェッチする機能を持たない（または許可リスト制）
* Rate limit：外部ソース叩きすぎ防止（特にオンデマンド取得の場合）
* 監査ログ：tools/callの引数と結果メタ（本文そのものは保存方針次第）を記録

---

### 9. 非機能要件

* 性能（目標）

  * 数値目標は設定しない。外部APIの応答時間とインメモリキャッシュのヒット有無に依存するため、可能な範囲で低遅延を目指す。
* 可用性

  * 外部データソース障害時は、メモリキャッシュが残っている範囲でのみ継続提供する（再起動後は保証しない）。
* 運用性

  * 定期更新ジョブは持たない（オンデマンド取得のため）
  * MCPサーバのヘルスチェックエンドポイント（HTTP運用時）

---

### 10. 受入基準（例）

* SCP番号→ページ取得が再現性を持つ（同一入力で同一ページが返る）
* 取得結果に必ず `source_url`・`license(CC BY-SA 3.0)`・`attribution` が含まれる ([SCP Foundation][6])
* 検索が `limit` を尊重し、絞り込み（tag等）が機能する
* stdio/HTTPいずれのトランスポートでもMCPクライアントから `tools/list` → `tools/call` が成功する ([Model Context Protocol][5])

---

[1]: https://scp-data.tedivm.com/ "SCP Data API | scp-api"
[2]: https://github.com/FiftyNine/scpper-web "GitHub - FiftyNine/scpper-web: Web Interface for SCP crawler database"
[3]: https://jsapi.wikidot.com/ "Wikidot JSapi"
[4]: https://modelcontextprotocol.io/specification/2025-11-25 "Specification - Model Context Protocol"
[5]: https://modelcontextprotocol.io/docs/learn/architecture "Architecture overview - Model Context Protocol"
[6]: https://scp-wiki.wikidot.com/licensing-guide "Licensing Guide - SCP Foundation"
[7]: https://scp-data.tedivm.com/data/scp/items/content_index.json "scp-data.tedivm.com"
